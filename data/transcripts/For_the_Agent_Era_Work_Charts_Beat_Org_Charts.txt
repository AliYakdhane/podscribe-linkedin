Today on the AI Daily Brief, in the age of AI and agents, here's why work charts beat org charts. The AI Daily Brief is a daily podcast and video about the most important news and discussions in AI. All right friends, quick announcements before we dive in. First of all, thank you to today's sponsors, Vanta, Robots & Pencils, Blitzy, and Superintelligent. To get an ad-free version of the show, go to patreon.com slash AI Daily Brief. And to learn about our incredibly exciting brand of creative sponsorship opportunities, shoot a note over to sponsors at aidailybrief.ai. All right, so I am very excited for this edition of the Long Read Sunday slash Big Think Style weekend episode. This one is coming out on my birthday, so I wanted to do something fun with it. And I recently ran across this idea that was just instantly resonant to me, and I think will be to a lot of you as well, especially those of you who are trying to figure out how to make AI, and particularly agents, work inside your organizations and enterprises. The original source of this was actually another podcast. For those of you who don't listen to Lenny's podcast, you absolutely should. Lenny Ruchitsky always has really interesting people on with a heavy concentration around product and product management, but not exclusively. And he recently had a conversation with Microsoft's AI platform product lead, Asha Sharma. Sharma said something which was at once blisteringly obvious, but at the same time, super interesting. The org chart starts to become the work chart. Tasks and throughput become more important than they have before. You just don't need as many layers. Sharma continued, you're not going to start to think in hierarchy and communicating upward. You're going to start to figure out like kind of outward task based type of opportunities. Business Insider continued, the big shift she added is also in the questions that companies will face. How do you automatically decide where to route a task? Who should take it on? How do you monitor whether an agent is doing it right and fine tune it if it's not? Summing up, she said, I believe that when AI agents are embedded across workflows, the structure of work naturally shifts from static hierarchies to dynamic throughput. That doesn't mean fewer jobs. It means different jobs. Now, this, of course, gets at one of the great questions of the time, which is how AI is going to impact the workplace. There is incredible anxiety right now around AI related job displacement. We talked about it a little bit on Friday when we were talking about OpenAI's new jobs board. And part of what makes this moment difficult is that it's easier to see which parts of the work that we do are going to be replaced by agents than it is to understand how new types of work are going to open up with agents. And so I think shifting our paradigm and trying where we can to move out of old modes of thinking into new ways of thinking can be really valuable. Now, Sharma didn't go all that deep into what a work chart even means. So for this Big Think episode, I wanted to go off and expand what that might look like and what it might mean. Now, the org chart itself has an illustrious history. You might have seen this incredible chart that's on your screen now, which is back from the mid 1850s. The organizational chart was invented in 1855 by Daniel McCallum, who was a Scottish-American engineer who served as the general superintendent of the New York and Erie Railroad. The original chart was compiled and drawn by civil engineer George Holt Henshaw, and was designed to solve very specific problems. The Erie Railroad had just incredible organizational challenges at this point in history. They had over 500 miles of railway track that spanned from New York through northern New Jersey and Pennsylvania to Lake Erie, and it was among the largest companies of its era. Its huge scale created complex information management problems, things like which superintendents oversaw specific tracks, how to coordinate schedules, and how to manage the hierarchy between conductors, laborers, and brakemen. In his 1856 report to stockholders, McCallum explained, "...a superintendent of a road only 50 miles in length can give the business his personal professional attention. But in governing 500 miles of track, a very different challenge exists." So this org chart helped try to delegate and organize those relationships in between. Now by the end of that century, the type of org chart that we have become incredibly accustomed to had become commonplace for companies of the time. What you're seeing is the org chart for IBM before it was IBM back in 1896, and you can probably recognize that common pyramid-style org structure that has stayed with us even to today. The problem of course is that in the agent era the org chart is breaking. For example, org charts are static. They freeze authority. However, agents are dynamic. They make capacity fluid and task-level. What's more, agents unbundle roles into tasks. The recognizable atomic unit of work in the agentic era is not job descriptions, but instead tasks and workflows. That means that the information being communicated with the org chart isn't necessarily the information that's relevant when it comes to understanding how specific streams of work get done. Work increasingly flows across teams, as well as across systems and data sources. Org charts capture authority, but not the flows of how key work actually happens. What's more, while org charts prioritize monolithic relationships, reporting structures that are fairly persistent over time, the reality is that task-level work relationships only need to exist long enough to accomplish a goal. Different sets of tasks could come together in different configurations, bundle themselves into a complete workstream to accomplish a goal, and then go away to do other things. There's also the complicating fact that in the agent era everyone becomes a manager. Every human employee is over time going to have big sets of agents that they orchestrate in an ongoing and dynamic basis, adding significant complications to trying to get all of that information into the org chart. So what is a work chart? Obviously this is a concept more than something that people have super put into place. So here I'm articulating kind of the most simplistic version of this. When I think about a work chart, I think about a simple map of steps from trigger to outcome. Trigger, step one, step two, et cetera, all the way over to achieving a goal. Each step probably has an articulation of who or what does it. Is it a human? Is it an agent? Is it a hybrid process? Work charts likely have targets that define success, as well as rules that the work must follow. So by way of a super simple example, let's think about the creation of a daily podcast. Let's say that the trigger for this specific work is that the master file is ready. I've completed the episode, it's been edited, and it's sitting there ready for what comes next. Well, the steps might be something like publishing, which depending on how things have been set up, could be done by an agent. Promoting, which could be either all-identic or a hybrid process where an agent automatically drafts posts based on the transcript, but then I'm the one to make the final decision about what goes up. Or I could just let it do the whole thing. And then maybe there's a review process to feed back into the future system where some combination of an agent and myself have access to the analytics to understand how a particular episode did. In this chart, the success target might be something like when in the day it needs to happen and the rules could be anything from the ads being correctly in place before it gets published to the compute spend for all the work around it. Although in the case of this type of very simplistic agent, I don't think that would be a big concern. You get the idea. You have a simple chart, again, from trigger to outcome with an indicator of who does what with the who being either agents or humans or both, success targets and rules. That's the basic idea that I had when I was thinking through this. As a founder, you're moving fast towards product market fit, your next round or your first big enterprise deal. But with AI accelerating how quickly startups build and ship, security expectations are higher earlier than ever. Getting security and compliance right can unlock growth or stall it if you wait too long. With deep integrations and automated workflows built for fast moving teams, Vantage gets you audit ready fast and keeps you secure with continuous monitoring as your models, infra and customers evolve. Fast growing customers like Langchain, Writer and Cursor trusted Vanta to build a scalable foundation from the start. And look, as someone who lives in the world of enterprise procurement, I love how Vanta makes it easy to get compliance right. The last thing you need when you're trying to win that big deal is to have it scuttled by something that Vanta has solved for over 10,000 companies. Go to Vanta.com slash NLW to save $1,000 today through the Vanta for Startups program and join over 10,000 ambitious companies already scaling with Vanta. That's V-A-N-T-A dot com slash NLW to save $1,000 for a limited time. Today's episode is brought to you by Robots and Pencils. When competitive advantage lasts mere moments, speed to value wins the AI race. While big consultancies bury progress under layers of process, Robots and Pencils builds impact at AI speed. They partner with clients to enhance human potential through AI, modernizing apps, strengthening data pipelines and accelerating cloud transformation. With AWS certified teams across US, Canada, Europe, and Latin America, clients get local expertise and global scale. And with a laser focus on real outcomes, their solutions help organizers work smarter and serve customers better. They're your nimble, high service alternative to big integrators. Turn your AI vision into value fast. Stay ahead with a partner built for progress. Partner with Robots and Pencils at RobotsandPencils.com. This episode is brought to you by Blitzi, the enterprise autonomous software development platform with infinite code context. Blitzi uses thousands of specialized AI agents that think for hours to understand enterprise scale code bases with millions of lines of code. Enterprise engineering leaders start every development sprint with the Blitzi platform, bringing in their development requirements. The Blitzi platform provides a plan, then generates and pre-compiles code for each task. Blitzi delivers 80% plus of the development work autonomously while providing a guide for the final 20% of human development work required to complete the sprint. Public companies are achieving a 5X engineering velocity increase when incorporating Blitzi as their pre-IDE development tool, pairing it with their coding copilot of choice to bring an AI native STLC into their org. Blitzi is providing a limited time 30 day free proof of concept for qualifying enterprises. The team will provide a 5X velocity increase on a real development project in your org. Visit Blitzi.com and press book demo to learn how Blitzi transforms your STLC from AI assisted to AI native. That's B-L-I T-Z-Y dot com. Now this is obviously offered very much in the spirit of experimentation and discussion. Now those of you who have used the N8Ns and Lindys of the world might note that this kind of looks like the workflows you set up when you were creating automations. And I think that that makes intuitive sense. The difference here is simply that you're expanding it from describing the set of sequences that exclusively an agent has to do to trying to zoom out to workflows that can actually cut across humans and agents in the enterprise context. In other words, there's a shared logic here and almost even a similar interface. But while each of these things is trying to communicate a sequence of steps that are required to get a particular group of work done, the type of work chart that we're talking about exists to bridge between human and digital employees. Now, of course, this is all offered very much in the spirit of collaboration and experimentation. Of the things that I am smart about, I would put organizational anything very near the bottom of the list. And yet, for the sake of having some fun practical aspect of this, I wanted to give an example of how you might go build your first work chart if only to come back and share better ways to do things. So first, I would suggest picking one specific value stream or outcome. Again, mine was this daily podcast publishing and promotion. But pick something that is actually integral to your work. Could be a type of code review. It could be a type of research or daily information gathering. Really anything that has a clear goal. Next, draw those three to seven steps left to right. Trigger, then step, then the next step, etc. Basically, try to keep this linear for the sake of communication because this is kind of a visual thing. You maybe want to share this with others. So again, trigger, step, step, step, outcome. Then under each step, label who or what is responsible for completing that step. Is it a human? Is it an agent? Is it a hybrid? You can use your own role names if you prefer. You can even get a little bit more complex and label what actor executes the task, but who is ultimately accountable. Because maybe in your organization, even when an agent is doing a task, there is still someone who is accountable for that task. And so now you've got the work stream. You've got the steps articulating how it happens. You've got the parties who are responsible for executing the steps and or ultimately accountable. And then you add the success targets and the rules. The success target is going to be some combination of a metric, a threshold, a time and or a scope. Again, mine was publishing an episode by a certain time. Other workflows are going to have their own success targets. And then where relevant and there may not always be relevant rules, but place rules that includes what the rule is and what action should happen if a rule isn't followed. So maybe, for example, with a research consideration, if a certain threshold of information hasn't been curated, maybe it doesn't get forwarded on to the reviewer. Lastly, and I think this is really important, this is not meant to be a static thing. These are meant to be updated frequently. Treat the work chart as living, not final. And over time, change things out, change a step, change a label, change a rule, change who's accountable. This is going to naturally follow, I think, the way that work actually happens. And I think the idea is that over time, you start to see your organization not as a collection of roles that have assumptions about authority within those roles, and assumptions about historic sets of tasks that were the Ballywick of those roles. But instead, we're going to start to see organizations as sets of tasks and goals to be accomplished, and relationships of work and task execution to get those goals done. As I was thinking about this, it seems like in this framework, we're likely to see new types of roles and new types of governance. There's, of course, things like agent ops, which is something that lots of people are talking about. That's all the operational work around configuring agents, setting budgets, working on observability, monitoring, evaluation, etc. But you also might see new types of roles that are basically agent managers, but with a different type of focus than we've previously thought about managers. A better name, for example, might be like work steward. That would be someone who owns the map of the work for a particular value stream, and measures the efficiency and the success of the flow to achieving that particular value stream's goal. Likewise, we're likely to see changes in the KPIs if we start to embrace this new type of approach. So a couple that seem interesting right away are things like agent coverage ratio. This would be in any given work chart, what is the percentage of steps that have an agent responsible? Are we trying explicitly to increase the agent coverage ratio? Or for a particular work stream, does that not actually matter? And it's more just about overall efficiency. It seems likely to me that there will be certain tasks where agent coverage ratio is really important, where because of their roteness, or complexity, or difficulty, or just time consuming-ness, the higher the percentage of steps that you can hand off to an agent, the better. Another related KPI might be something like the human in the loop rate, which would be the percentage of the steps that actually require human approval. You might have KPIs around how often the rules are followed, i.e. a guardrail breach rate. You could have KPIs around escalation and where humans get involved. Obviously you can have KPIs around the time and cost per unit of outcome. So that's the concept. Simply put, it's to stop thinking in terms of traditional organizational structures and to start thinking in terms of how tasks interact with one another to achieve goals. To be clear, I am wildly oversimplifying complex things here. All of this is just experimental, and all of this is offered in the spirit of an interesting thought experiment, but I'm really interested to know what you think. Again, where the original source and inspiration for this was the Lenny's podcast episode with Microsoft AI Platform product lead Asha Sharma, so go check that out. For now, though, that's going to do it for today's AI Daily Brief. Appreciate you listening as always, and until next time, peace.